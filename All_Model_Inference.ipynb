{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "3tqvXl8oQwUR",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dataset\n",
      "  Downloading dataset-1.6.2-py2.py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting sqlalchemy<2.0.0,>=1.3.2 (from dataset)\n",
      "  Downloading SQLAlchemy-1.4.52-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Collecting alembic>=0.6.2 (from dataset)\n",
      "  Downloading alembic-1.13.1-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting banal>=1.0.1 (from dataset)\n",
      "  Downloading banal-1.0.6-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting Mako (from alembic>=0.6.2->dataset)\n",
      "  Downloading Mako-1.3.3-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4 in /opt/conda/lib/python3.10/site-packages (from alembic>=0.6.2->dataset) (4.9.0)\n",
      "Collecting greenlet!=0.4.17 (from sqlalchemy<2.0.0,>=1.3.2->dataset)\n",
      "  Downloading greenlet-3.0.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /opt/conda/lib/python3.10/site-packages (from Mako->alembic>=0.6.2->dataset) (2.1.3)\n",
      "Downloading dataset-1.6.2-py2.py3-none-any.whl (18 kB)\n",
      "Downloading alembic-1.13.1-py3-none-any.whl (233 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading banal-1.0.6-py2.py3-none-any.whl (6.1 kB)\n",
      "Downloading SQLAlchemy-1.4.52-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading greenlet-3.0.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (616 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m616.0/616.0 kB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading Mako-1.3.3-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: banal, Mako, greenlet, sqlalchemy, alembic, dataset\n",
      "Successfully installed Mako-1.3.3 alembic-1.13.1 banal-1.0.6 dataset-1.6.2 greenlet-3.0.3 sqlalchemy-1.4.52\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting trl\n",
      "  Downloading trl-0.8.6-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: torch>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from trl) (2.2.0)\n",
      "Collecting transformers>=4.31.0 (from trl)\n",
      "  Downloading transformers-4.40.2-py3-none-any.whl.metadata (137 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.0/138.0 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.18.2 in /opt/conda/lib/python3.10/site-packages (from trl) (1.26.3)\n",
      "Collecting accelerate (from trl)\n",
      "  Downloading accelerate-0.30.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting datasets (from trl)\n",
      "  Downloading datasets-2.19.1-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting tyro>=0.5.11 (from trl)\n",
      "  Downloading tyro-0.8.4-py3-none-any.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (4.9.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (2023.12.2)\n",
      "Collecting huggingface-hub<1.0,>=0.19.3 (from transformers>=4.31.0->trl)\n",
      "  Downloading huggingface_hub-0.23.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl) (6.0.1)\n",
      "Collecting regex!=2019.12.17 (from transformers>=4.31.0->trl)\n",
      "  Downloading regex-2024.5.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl) (2.31.0)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers>=4.31.0->trl)\n",
      "  Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers>=4.31.0->trl)\n",
      "  Downloading safetensors-0.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl) (4.65.0)\n",
      "Collecting docstring-parser>=0.14.1 (from tyro>=0.5.11->trl)\n",
      "  Downloading docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting rich>=11.1.0 (from tyro>=0.5.11->trl)\n",
      "  Downloading rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting shtab>=1.5.6 (from tyro>=0.5.11->trl)\n",
      "  Downloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate->trl) (5.9.0)\n",
      "Collecting pyarrow>=12.0.0 (from datasets->trl)\n",
      "  Downloading pyarrow-16.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting pyarrow-hotfix (from datasets->trl)\n",
      "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets->trl)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pandas (from datasets->trl)\n",
      "  Downloading pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "Collecting xxhash (from datasets->trl)\n",
      "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess (from datasets->trl)\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Collecting aiohttp (from datasets->trl)\n",
      "  Downloading aiohttp-3.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets->trl)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl) (23.1.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets->trl)\n",
      "  Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets->trl)\n",
      "  Downloading multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets->trl)\n",
      "  Downloading yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
      "Collecting async-timeout<5.0,>=4.0 (from aiohttp->datasets->trl)\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.31.0->trl) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.31.0->trl) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.31.0->trl) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.31.0->trl) (2023.11.17)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=11.1.0->tyro>=0.5.11->trl)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (2.15.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.4.0->trl) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->trl) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->trl) (2023.3.post1)\n",
      "Collecting tzdata>=2022.7 (from pandas->datasets->trl)\n",
      "  Downloading tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.4.0->trl) (1.3.0)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets->trl) (1.16.0)\n",
      "Downloading trl-0.8.6-py3-none-any.whl (245 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.2/245.2 kB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.40.2-py3-none-any.whl (9.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tyro-0.8.4-py3-none-any.whl (102 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.4/102.4 kB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading accelerate-0.30.1-py3-none-any.whl (302 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.6/302.6 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading datasets-2.19.1-py3-none-any.whl (542 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m85.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
      "Downloading aiohttp-3.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m63.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.23.0-py3-none-any.whl (401 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.2/401.2 kB\u001b[0m \u001b[31m102.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-16.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (40.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.5.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (774 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m774.1/774.1 kB\u001b[0m \u001b[31m107.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.7/240.7 kB\u001b[0m \u001b[31m84.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m91.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading shtab-1.7.1-py3-none-any.whl (14 kB)\n",
      "Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m74.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
      "Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m96.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (239 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.5/239.5 kB\u001b[0m \u001b[31m106.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.3/124.3 kB\u001b[0m \u001b[31m68.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.4/345.4 kB\u001b[0m \u001b[31m124.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.6/301.6 kB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: xxhash, tzdata, shtab, safetensors, regex, pyarrow-hotfix, pyarrow, multidict, mdurl, frozenlist, docstring-parser, dill, async-timeout, yarl, pandas, multiprocess, markdown-it-py, huggingface-hub, aiosignal, tokenizers, rich, aiohttp, accelerate, tyro, transformers, datasets, trl\n",
      "Successfully installed accelerate-0.30.1 aiohttp-3.9.5 aiosignal-1.3.1 async-timeout-4.0.3 datasets-2.19.1 dill-0.3.8 docstring-parser-0.16 frozenlist-1.4.1 huggingface-hub-0.23.0 markdown-it-py-3.0.0 mdurl-0.1.2 multidict-6.0.5 multiprocess-0.70.16 pandas-2.2.2 pyarrow-16.0.0 pyarrow-hotfix-0.6 regex-2024.5.10 rich-13.7.1 safetensors-0.4.3 shtab-1.7.1 tokenizers-0.19.1 transformers-4.40.2 trl-0.8.6 tyro-0.8.4 tzdata-2024.1 xxhash-3.4.1 yarl-1.9.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting peft\n",
      "  Downloading peft-0.10.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft) (23.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft) (2.2.0)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft) (4.40.2)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft) (4.65.0)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.30.1)\n",
      "Requirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft) (0.4.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.17.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.23.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2023.12.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (4.9.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2024.5.10)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (0.19.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2023.11.17)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n",
      "Downloading peft-0.10.0-py3-none-any.whl (199 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.1/199.1 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: peft\n",
      "Successfully installed peft-0.10.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting transformers==4.40.0\n",
      "  Downloading transformers-4.40.0-py3-none-any.whl.metadata (137 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.6/137.6 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.40.0) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers==4.40.0) (0.23.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.40.0) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.40.0) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.40.0) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.40.0) (2024.5.10)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.40.0) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers==4.40.0) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.40.0) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.40.0) (4.65.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.40.0) (2023.12.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.40.0) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.40.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.40.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.40.0) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.40.0) (2023.11.17)\n",
      "Downloading transformers-4.40.0-py3-none-any.whl (9.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m89.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: transformers\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.40.2\n",
      "    Uninstalling transformers-4.40.2:\n",
      "      Successfully uninstalled transformers-4.40.2\n",
      "Successfully installed transformers-4.40.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting accelerate==0.29.3\n",
      "  Downloading accelerate-0.29.3-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.29.3) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.29.3) (23.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate==0.29.3) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate==0.29.3) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.29.3) (2.2.0)\n",
      "Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate==0.29.3) (0.23.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.29.3) (0.4.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.29.3) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.29.3) (4.9.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.29.3) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.29.3) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.29.3) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.29.3) (2023.12.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate==0.29.3) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate==0.29.3) (4.65.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate==0.29.3) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate==0.29.3) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate==0.29.3) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate==0.29.3) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate==0.29.3) (2023.11.17)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate==0.29.3) (1.3.0)\n",
      "Downloading accelerate-0.29.3-py3-none-any.whl (297 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.6/297.6 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: accelerate\n",
      "  Attempting uninstall: accelerate\n",
      "    Found existing installation: accelerate 0.30.1\n",
      "    Uninstalling accelerate-0.30.1:\n",
      "      Successfully uninstalled accelerate-0.30.1\n",
      "Successfully installed accelerate-0.29.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting accelerated-scan==0.1.2\n",
      "  Downloading accelerated_scan-0.1.2-py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: torch>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from accelerated-scan==0.1.2) (2.2.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=2.1.0->accelerated-scan==0.1.2) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=2.1.0->accelerated-scan==0.1.2) (4.9.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=2.1.0->accelerated-scan==0.1.2) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=2.1.0->accelerated-scan==0.1.2) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=2.1.0->accelerated-scan==0.1.2) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=2.1.0->accelerated-scan==0.1.2) (2023.12.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=2.1.0->accelerated-scan==0.1.2) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=2.1.0->accelerated-scan==0.1.2) (1.3.0)\n",
      "Downloading accelerated_scan-0.1.2-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: accelerated-scan\n",
      "Successfully installed accelerated-scan-0.1.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting flash-attn==2.5.7\n",
      "  Downloading flash_attn-2.5.7.tar.gz (2.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0mm00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from flash-attn==2.5.7) (2.2.0)\n",
      "Collecting einops (from flash-attn==2.5.7)\n",
      "  Downloading einops-0.8.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from flash-attn==2.5.7) (23.1)\n",
      "Collecting ninja (from flash-attn==2.5.7)\n",
      "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn==2.5.7) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn==2.5.7) (4.9.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn==2.5.7) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn==2.5.7) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn==2.5.7) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn==2.5.7) (2023.12.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->flash-attn==2.5.7) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->flash-attn==2.5.7) (1.3.0)\n",
      "Downloading einops-0.8.0-py3-none-any.whl (43 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: flash-attn\n",
      "  Building wheel for flash-attn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for flash-attn: filename=flash_attn-2.5.7-cp310-cp310-linux_x86_64.whl size=120853563 sha256=bbe6f77fd0899f8a125a5bdcf734b660c4c88e81c9b51c7ce98ebeba44dc6fa0\n",
      "  Stored in directory: /root/.cache/pip/wheels/13/96/ed/bcac89c56b606421f99b45b16a94db5d0f2b6b4eaf8bac4d01\n",
      "Successfully built flash-attn\n",
      "Installing collected packages: ninja, einops, flash-attn\n",
      "Successfully installed einops-0.8.0 flash-attn-2.5.7 ninja-1.11.1.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting mamba-ssm==1.2.0.post1\n",
      "  Downloading mamba_ssm-1.2.0.post1.tar.gz (34 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from mamba-ssm==1.2.0.post1) (2.2.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from mamba-ssm==1.2.0.post1) (23.1)\n",
      "Requirement already satisfied: ninja in /opt/conda/lib/python3.10/site-packages (from mamba-ssm==1.2.0.post1) (1.11.1.1)\n",
      "Requirement already satisfied: einops in /opt/conda/lib/python3.10/site-packages (from mamba-ssm==1.2.0.post1) (0.8.0)\n",
      "Requirement already satisfied: triton in /opt/conda/lib/python3.10/site-packages (from mamba-ssm==1.2.0.post1) (2.2.0)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from mamba-ssm==1.2.0.post1) (4.40.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->mamba-ssm==1.2.0.post1) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch->mamba-ssm==1.2.0.post1) (4.9.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->mamba-ssm==1.2.0.post1) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->mamba-ssm==1.2.0.post1) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->mamba-ssm==1.2.0.post1) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->mamba-ssm==1.2.0.post1) (2023.12.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers->mamba-ssm==1.2.0.post1) (0.23.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers->mamba-ssm==1.2.0.post1) (1.26.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers->mamba-ssm==1.2.0.post1) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->mamba-ssm==1.2.0.post1) (2024.5.10)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers->mamba-ssm==1.2.0.post1) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers->mamba-ssm==1.2.0.post1) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers->mamba-ssm==1.2.0.post1) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers->mamba-ssm==1.2.0.post1) (4.65.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->mamba-ssm==1.2.0.post1) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->mamba-ssm==1.2.0.post1) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->mamba-ssm==1.2.0.post1) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->mamba-ssm==1.2.0.post1) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->mamba-ssm==1.2.0.post1) (2023.11.17)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->mamba-ssm==1.2.0.post1) (1.3.0)\n",
      "Building wheels for collected packages: mamba-ssm\n",
      "  Building wheel for mamba-ssm (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for mamba-ssm: filename=mamba_ssm-1.2.0.post1-cp310-cp310-linux_x86_64.whl size=137750683 sha256=b264292652a34fb9dd0ce880a34a4407ba7256a3338388d056769ec29a4581c9\n",
      "  Stored in directory: /root/.cache/pip/wheels/22/6e/60/ddd5c574b5793a30028f2cabdacd2a3ec2276edaaa8c00fd35\n",
      "Successfully built mamba-ssm\n",
      "Installing collected packages: mamba-ssm\n",
      "Successfully installed mamba-ssm-1.2.0.post1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting causal-conv1d==1.2.0.post1\n",
      "  Downloading causal_conv1d-1.2.0.post1.tar.gz (7.1 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from causal-conv1d==1.2.0.post1) (2.2.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from causal-conv1d==1.2.0.post1) (23.1)\n",
      "Requirement already satisfied: ninja in /opt/conda/lib/python3.10/site-packages (from causal-conv1d==1.2.0.post1) (1.11.1.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->causal-conv1d==1.2.0.post1) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch->causal-conv1d==1.2.0.post1) (4.9.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->causal-conv1d==1.2.0.post1) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->causal-conv1d==1.2.0.post1) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->causal-conv1d==1.2.0.post1) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->causal-conv1d==1.2.0.post1) (2023.12.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->causal-conv1d==1.2.0.post1) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->causal-conv1d==1.2.0.post1) (1.3.0)\n",
      "Building wheels for collected packages: causal-conv1d\n",
      "  Building wheel for causal-conv1d (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for causal-conv1d: filename=causal_conv1d-1.2.0.post1-cp310-cp310-linux_x86_64.whl size=45616899 sha256=1ae593512d69031a8156602a5d0c324b931a561bc07a2f3a91b6d33b6fdcfcae\n",
      "  Stored in directory: /root/.cache/pip/wheels/27/a0/30/2ba5687ad92de1a7f3ae2e2a97d54f3364546051dc5d6eafde\n",
      "Successfully built causal-conv1d\n",
      "Installing collected packages: causal-conv1d\n",
      "Successfully installed causal-conv1d-1.2.0.post1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install dataset\n",
    "!pip install trl\n",
    "!pip install peft\n",
    "!pip install transformers==4.40.0\n",
    "!pip install accelerate==0.29.3\n",
    "!pip install accelerated-scan==0.1.2\n",
    "!pip install flash-attn==2.5.7\n",
    "!pip install mamba-ssm==1.2.0.post1\n",
    "!pip install causal-conv1d==1.2.0.post1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==4.40.2\n",
      "  Using cached transformers-4.40.2-py3-none-any.whl.metadata (137 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.40.2) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers==4.40.2) (0.23.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.40.2) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.40.2) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.40.2) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.40.2) (2024.5.10)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.40.2) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers==4.40.2) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.40.2) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.40.2) (4.65.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.40.2) (2023.12.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.40.2) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.40.2) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.40.2) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.40.2) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.40.2) (2023.11.17)\n",
      "Using cached transformers-4.40.2-py3-none-any.whl (9.0 MB)\n",
      "Installing collected packages: transformers\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.40.0\n",
      "    Uninstalling transformers-4.40.0:\n",
      "      Successfully uninstalled transformers-4.40.0\n",
      "Successfully installed transformers-4.40.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install transformers==4.40.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "rH0ksRn2Ryld"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from trl import SFTTrainer\n",
    "from peft import LoraConfig, PeftModel\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments\n",
    "import pickle\n",
    "from datasets import Dataset\n",
    "from transformers import default_data_collator\n",
    "from tqdm import tqdm\n",
    "from transformers import BitsAndBytesConfig\n",
    "import torch\n",
    "from huggingface_hub import login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qJYp1vQXkb7C",
    "outputId": "2c28e16c-ce34-4ccc-9e7e-7a8e4e5eb34c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "login(token = \"#\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DNlhCKnmj34O"
   },
   "source": [
    "#Must use high RAM. T4 is enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YlN94vekR4ZV",
    "outputId": "c447750c-1bb9-40cf-8611-aedf1637aa06"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at tri-ml/mamba-7b-rw were not used when initializing MambaForCausalLM: ['model.lm_head.weight']\n",
      "- This IS expected if you are initializing MambaForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MambaForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n#LLAMA3 8B Does not run on T4\\ntokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Meta-Llama-3-8B\",torch_dtype=torch.float16)\\nmodel = AutoModelForCausalLM.from_pretrained(\"meta-llama/Meta-Llama-3-8B\",torch_dtype=torch.float16)\\n\\ndel model\\ndel tokenizer\\n\\n#stabilityai/\\ntokenizer = AutoTokenizer.from_pretrained(\"stabilityai/stablelm-zephyr-3b\",torch_dtype=torch.float16)\\nmodel = AutoModelForCausalLM.from_pretrained(\"stabilityai/stablelm-zephyr-3b\",torch_dtype=torch.float16)\\n\\ndel model\\ndel tokenizer\\n\\n#Recurrent Gemma\\ntokenizer = AutoTokenizer.from_pretrained(\"google/recurrentgemma-2b\",torch_dtype=torch.float16)\\nmodel = AutoModelForCausalLM.from_pretrained(\"google/recurrentgemma-2b\",torch_dtype=torch.float16)\\nprint(\\'here\\')\\ndel model\\ndel tokenizer\\n\\n#Gemma 2B\\ntokenizer = AutoTokenizer.from_pretrained(\"google/gemma-2b\",torch_dtype=torch.float16)\\nmodel = AutoModelForCausalLM.from_pretrained(\"google/gemma-2b\",torch_dtype=torch.float16)\\n\\ndel model\\ndel tokenizer\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#Mamba 2.8B\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"state-spaces/mamba-2.8b-hf\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"state-spaces/mamba-2.8b-hf\")\n",
    "del model\n",
    "del tokenizer\n",
    "'''\n",
    "#Mamba 7B\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"tri-ml/mamba-7b-rw\",torch_dtype=torch.float16)\n",
    "model = AutoModelForCausalLM.from_pretrained(\"tri-ml/mamba-7b-rw\",torch_dtype=torch.float16)\n",
    "#del model\n",
    "#del tokenizer\n",
    "'''\n",
    "#Mamba 1.4B\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"state-spaces/mamba-1.4b-hf\",torch_dtype=torch.float16)\n",
    "model = AutoModelForCausalLM.from_pretrained(\"state-spaces/mamba-1.4b-hf\",torch_dtype=torch.float16)\n",
    "del model\n",
    "del tokenizer\n",
    "\n",
    "#LLAMA2-7B\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-hf\",torch_dtype=torch.float16)\n",
    "model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-2-7b-hf\",torch_dtype=torch.float16)\n",
    "\n",
    "del model\n",
    "del tokenizer\n",
    "'''\n",
    "#Mistral-7B\n",
    "#tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-v0.1\",torch_dtype=torch.float16)\n",
    "#model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-v0.1\",torch_dtype=torch.float16)\n",
    "\n",
    "#del model\n",
    "#del tokenizer\n",
    "'''\n",
    "#LLAMA3 8B Does not run on T4\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Meta-Llama-3-8B\",torch_dtype=torch.float16)\n",
    "model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Meta-Llama-3-8B\",torch_dtype=torch.float16)\n",
    "\n",
    "del model\n",
    "del tokenizer\n",
    "\n",
    "#stabilityai/\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"stabilityai/stablelm-zephyr-3b\",torch_dtype=torch.float16)\n",
    "model = AutoModelForCausalLM.from_pretrained(\"stabilityai/stablelm-zephyr-3b\",torch_dtype=torch.float16)\n",
    "\n",
    "del model\n",
    "del tokenizer\n",
    "\n",
    "#Recurrent Gemma\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/recurrentgemma-2b\",torch_dtype=torch.float16)\n",
    "model = AutoModelForCausalLM.from_pretrained(\"google/recurrentgemma-2b\",torch_dtype=torch.float16)\n",
    "print('here')\n",
    "del model\n",
    "del tokenizer\n",
    "\n",
    "#Gemma 2B\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-2b\",torch_dtype=torch.float16)\n",
    "model = AutoModelForCausalLM.from_pretrained(\"google/gemma-2b\",torch_dtype=torch.float16)\n",
    "\n",
    "del model\n",
    "del tokenizer\n",
    "'''\n",
    "#phi 1.5B \n",
    "\n",
    "#tokenizer = AutoTokenizer.from_pretrained(\"microsoft/phi-1_5\",torch_dtype=torch.float16)\n",
    "#model = AutoModelForCausalLM.from_pretrained(\"microsoft/phi-1_5\",torch_dtype=torch.float16)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PwZeTporM-gW"
   },
   "source": [
    "#Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "2PLuzGGiUqGM"
   },
   "outputs": [],
   "source": [
    "model = model.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "m2JYAz9lRwKH"
   },
   "outputs": [],
   "source": [
    "model.generation_config.pad_token_id = model.generation_config.eos_token_id\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "tokenizer.padding_side = 'right'\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "i7LJO7HlUWx7"
   },
   "outputs": [],
   "source": [
    "inputs = tokenizer(\"You need to write a story about a beautiful girl, Make the story as long as possible. Start Story: \", return_tensors=\"pt\").to(model.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, Optional, Tuple, Union\n",
    "from transformers import MambaConfig\n",
    "class MambaCache:\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        config: MambaConfig\n",
    "        batch_size: int\n",
    "        dtype: torch.dtype\n",
    "        device: torch.device\n",
    "\n",
    "    Attributes:\n",
    "        seqlen_offset: int\n",
    "        dtype: torch.dtype\n",
    "        conv_states: Dict[int, torch.Tensor] # layer_idx -> [batch_size, intermediate_size, conv_kernel_size]\n",
    "        ssm_states: Dict[int, torch.Tensor] # layer_idx -> [batch_size, intermediate_size, ssm_state_size]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, config: MambaConfig, batch_size: int, dtype: torch.dtype = torch.float16, device: Optional[str] = None\n",
    "    ):\n",
    "        self.seqlen_offset = 0\n",
    "        self.dtype = dtype\n",
    "        intermediate_size = config.intermediate_size\n",
    "        ssm_state_size = config.state_size\n",
    "        conv_kernel_size = config.conv_kernel\n",
    "\n",
    "        self.conv_states = {\n",
    "            i: torch.zeros(batch_size, intermediate_size, conv_kernel_size, device=device, dtype=dtype)\n",
    "            for i in range(config.num_hidden_layers)\n",
    "        }\n",
    "        self.ssm_states = {\n",
    "            i: torch.zeros(batch_size, intermediate_size, ssm_state_size, device=device, dtype=dtype)\n",
    "            for i in range(config.num_hidden_layers)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1394,   878,   281,  3630,   247,  2926,   670,   247,  5389,  3226,\n",
       "            13, 10338,   253,  2926,   347,  1048,   347,  1896,    15, 11075,\n",
       "         16061,    27,   209,   187,    14,   370,    18,    13,    25,  2222,\n",
       "          8979,    67,   412,    15,   681, 33397,  5382,    34,    15, 26006,\n",
       "          9552,    27,  2596, 19662,   187,    14,   370,    18,    13,    25,\n",
       "          2222,  8979,    67,   412,    15,   681, 33397,  5382,    34,    15,\n",
       "         26006,  9552,    27,  2596, 19662,   187,    14,   370,    18,    13,\n",
       "            25,  2222,  8979,    67,   412,    15,   681, 33397,  5382,    34,\n",
       "            15, 26006,  9552,    27,  2596, 19662,   187,    14,   370,    18,\n",
       "            13,    25,  2222,  8979,    67,   412,    15,   681, 33397,  5382,\n",
       "            34,    15, 26006,  9552,    27,  2596, 19662,   187,    14,   370,\n",
       "            18,    13,    25,  2222,  8979,    67,   412,    15,   681, 33397,\n",
       "          5382,    34,    15, 26006,  9552,    27,  2596, 19662]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generate(inputs['input_ids'], max_length=128, cache_params =MambaCache(model.config, 1, device = model.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n"
     ]
    }
   ],
   "source": [
    "print(len(outputs[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6umFszS_XD3q",
    "outputId": "d83fbdb3-d539-4a7f-d3fa-28a33b5fbb17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You need to write a story about a beautiful girl, Make the story as long as possible. Start Story: *************** Once upon a time there was a beautiful girl. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She was very beautiful. She\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_WmpH_L4NDWF"
   },
   "source": [
    "#Extracting Embading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "BrIeANh_NQbm"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G-C0Ax0xaRXp",
    "outputId": "0475705e-4524-483d-8e12-a1e81aee2bde"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"stabilityai/stablelm-zephyr-3b\",torch_dtype=torch.float16)\n",
    "model = AutoModel.from_pretrained(\"stabilityai/stablelm-zephyr-3b\",torch_dtype=torch.float16)\n",
    "#tokenizer = AutoTokenizer.from_pretrained(\"state-spaces/mamba-1.4b-hf\",torch_dtype=torch.float16)\n",
    "#model = AutoModelForCausalLM.from_pretrained(\"state-spaces/mamba-1.4b-hf\",torch_dtype=torch.float16)\n",
    "#tokenizer = AutoTokenizer.from_pretrained(\"google/recurrentgemma-2b\",torch_dtype=torch.float16)\n",
    "#model = AutoModelForCausalLM.from_pretrained(\"google/recurrentgemma-2b\",torch_dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "4Ed55XuxaXoU"
   },
   "outputs": [],
   "source": [
    "model = model.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "nlw-rGenagq7"
   },
   "outputs": [],
   "source": [
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\").to(model.device)\n",
    "model = model.eval()\n",
    "outputs = model(inputs['input_ids'],output_hidden_states =True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sKDHoT6la2zc"
   },
   "source": [
    "#Final Layer Embeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "UwtgSg-AanYw"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2560])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#outputs.last_hidden_state #for transformer\n",
    "outputs[\"hidden_states\"][-1][0,-1,:].shape #for mambas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NcSf5Chwd-Il"
   },
   "source": [
    "#Word Embeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "HX6cWpcObbNC"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0549, -0.2002, -0.0786,  ..., -0.0874,  0.0771,  0.0222],\n",
       "         [-0.0449, -0.0140,  0.0070,  ...,  0.1094,  0.1152, -0.0522],\n",
       "         [ 0.0435,  0.0062,  0.2637,  ...,  0.0903,  0.0664, -0.0430],\n",
       "         ...,\n",
       "         [-0.0693,  0.0723,  0.0747,  ...,  0.1187, -0.0236, -0.0938],\n",
       "         [-0.1455,  0.0796,  0.0015,  ...,  0.1367,  0.0603, -0.0045],\n",
       "         [ 0.0547,  0.0025, -0.0640,  ...,  0.1270, -0.0320,  0.1436]]],\n",
       "       device='cuda:0', dtype=torch.float16, grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_input_embeddings()(inputs['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
