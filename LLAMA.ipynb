{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6479c372",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saad/anaconda3/envs/cleanrl/lib/python3.9/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "from transformers import BigBirdForCausalLM, BigBirdConfig\n",
    "from transformers.modeling_outputs import CausalLMOutputWithCrossAttentions\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "import h5py\n",
    "import pickle\n",
    "import numpy as np\n",
    "from datagen.tokens import GLOBAL_TOKENS_MAP, GLOBAL_TOKENS_RMAP\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import default_data_collator\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from transformers import Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20d96150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom model configuration with fewer parameters\n",
    "config =  BigBirdConfig(\n",
    "    vocab_size=len(GLOBAL_TOKENS_MAP),  # Based on the number of unique tokens\n",
    "    hidden_size = 256,\n",
    "    intermediate_size = 256,\n",
    "    num_hidden_layers = 22,\n",
    "    num_attention_heads = 8,\n",
    "    max_position_embeddings = 128,\n",
    "    use_cache = True,\n",
    "    pad_token_id = 31,\n",
    "    bos_token_id = 30,\n",
    "    eos_token_id = 29,\n",
    "    rope_theta=20.0,\n",
    "    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8df48bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "If you want to use `BigBirdForCausalLM` as a standalone, add `is_decoder=True.`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters in the model: 8881184\n"
     ]
    }
   ],
   "source": [
    "model = BigBirdForCausalLM(config)\n",
    "\n",
    "# Calculate the number of parameters\n",
    "print(f\"Total parameters in the model: {model.num_parameters()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "309b05d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_data_collator(features):\n",
    "    batch = default_data_collator(features)\n",
    "    input_ids = [f['input_ids'] for f in features]\n",
    "\n",
    "    batch['input_ids'] = torch.tensor(input_ids, dtype=torch.long)\n",
    "    batch['labels'] = torch.tensor(input_ids, dtype=torch.long)  # labels same as input_ids for LM\n",
    "    #batch['labels'][:,:20] = -100\n",
    "    return batch\n",
    "\n",
    "# Use this custom collator in the DataLoader\n",
    "data_collator = custom_data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ae3678fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_from_pickle(filepath='dataset/addition_dataset.pkl'):\n",
    "    with open(filepath, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    return data['texts'],data['info']\n",
    "\n",
    "\n",
    "def prepare_dataset(texts,info):\n",
    "    train_size = int(0.8 * len(texts))\n",
    "    train_set = Dataset.from_dict({\n",
    "        'input_ids': texts[:train_size],\n",
    "        'info': info[:train_size]\n",
    "    })\n",
    "    test_set = Dataset.from_dict({\n",
    "        'input_ids': texts[train_size:],\n",
    "        'info': info[train_size:]\n",
    "    })\n",
    "    return train_set, test_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aeac8b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=30,\n",
    "    per_device_train_batch_size=64,\n",
    "    per_device_eval_batch_size=64,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    evaluation_strategy='epoch',\n",
    "    learning_rate=1e-4\n",
    ")\n",
    "texts,info = load_data_from_pickle()\n",
    "train_dataset, test_dataset = prepare_dataset(texts,info)\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    data_collator=data_collator\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0a87a975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoding function to transform tokens back to text using GLOBAL_TOKENS_MAP\n",
    "def decode(tokens):\n",
    "    return ' '.join(GLOBAL_TOKENS_MAP.get(token, \"\") for token in tokens if token in GLOBAL_TOKENS_MAP)\n",
    "\n",
    "\n",
    "def calculate_accuracy(dataset,model,boundary = 20):\n",
    "    print(decode(dataset[0]['input_ids'][:boundary]))\n",
    "    corr = 0\n",
    "    batch_size = 64\n",
    "    for i in tqdm(range(0, len(dataset), batch_size)):\n",
    "        #print(i)\n",
    "        bs = min(batch_size,len(dataset)-i)\n",
    "        predictions = model.generate(torch.tensor([dataset[j]['input_ids'][:boundary] for j in range(i,i+bs)]).to('cuda:0'), max_length=128, )\n",
    "        \n",
    "        for k in range(bs):    \n",
    "            pred = []\n",
    "            add = False\n",
    "            for j in predictions[k][boundary:].tolist():\n",
    "                if j == 15:\n",
    "                    break\n",
    "                if add:\n",
    "                    pred.append(j)\n",
    "                if j == 14:\n",
    "                    add = True\n",
    "                \n",
    "            if len(dataset[i+k]['info']) != len(pred):\n",
    "                continue\n",
    "            if dataset[i+k]['info'] == pred:\n",
    "                corr+=1\n",
    "    print(\"Accuracy: \",corr/len(dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "985c2e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attention type 'block_sparse' is not possible if sequence_length: 73 <= num global tokens: 2 * config.block_size + min. num sliding tokens: 3 * config.block_size + config.num_random_blocks * config.block_size + additional buffer: config.num_random_blocks * config.block_size = 704 with config.block_size = 64, config.num_random_blocks = 3. Changing attention type to 'original_full'...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3750' max='3750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3750/3750 19:35, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.744710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.446038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.394573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.730800</td>\n",
       "      <td>0.158895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.730800</td>\n",
       "      <td>0.007448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.730800</td>\n",
       "      <td>0.004403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.730800</td>\n",
       "      <td>0.003119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.013200</td>\n",
       "      <td>0.002374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.013200</td>\n",
       "      <td>0.001897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.013200</td>\n",
       "      <td>0.001575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.013200</td>\n",
       "      <td>0.001337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.001153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.001012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.000898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.000806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.000731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.000667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.000615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.000572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.000536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.000501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.000474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.000450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.000384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.000379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.000378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (ReadTimeout), entering retry loop.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results: {'eval_loss': 0.00037760258419439197, 'eval_runtime': 3.1142, 'eval_samples_per_second': 642.214, 'eval_steps_per_second': 10.275, 'epoch': 30.0}\n"
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Evaluation Results: {eval_results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3475343f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOS <prompt> 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 3 0 + 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 7 4 6 </prompt>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [04:01<00:00,  1.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.0\n",
      "BOS <prompt> 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 9 6 8 8 + 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 9 3 5 8 </prompt>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [00:59<00:00,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "calculate_accuracy(train_dataset,model, 22*2+4)\n",
    "calculate_accuracy(test_dataset,model, 22*2+4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "724ccd5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size:  6\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'addition_dataset6.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [27]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m21\u001b[39m):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSize: \u001b[39m\u001b[38;5;124m\"\u001b[39m,i)\n\u001b[0;32m----> 3\u001b[0m     texts, info \u001b[38;5;241m=\u001b[39m \u001b[43mload_data_from_pickle\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maddition_dataset\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     train_dataset, test_dataset \u001b[38;5;241m=\u001b[39m prepare_dataset(texts, info)\n\u001b[1;32m      5\u001b[0m     calculate_accuracy(test_dataset,model, \u001b[38;5;241m22\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m4\u001b[39m)\n",
      "Input \u001b[0;32mIn [22]\u001b[0m, in \u001b[0;36mload_data_from_pickle\u001b[0;34m(filepath)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_data_from_pickle\u001b[39m(filepath\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset/addition_dataset.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      3\u001b[0m         data \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtexts\u001b[39m\u001b[38;5;124m'\u001b[39m],data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minfo\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'addition_dataset6.pkl'"
     ]
    }
   ],
   "source": [
    "for i in range(6,21):\n",
    "    print(\"Size: \",i)\n",
    "    texts, info = load_data_from_pickle(f'addition_dataset{i}.pkl')\n",
    "    train_dataset, test_dataset = prepare_dataset(texts, info)\n",
    "    calculate_accuracy(test_dataset,model, 22*2+4)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edb0af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(texts):\n",
    "    return [GLOBAL_TOKENS_RMAP.get(words, \"\") for words in texts.split() if words in GLOBAL_TOKENS_RMAP]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4fa9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weights_path = 'LLAMA_512_512_44_16_80M.pt'\n",
    "torch.save(model.state_dict(), model_weights_path)\n",
    "model = LlamaForCausalLM(config)  # Make sure you use the correct model class\n",
    "model.load_state_dict(torch.load(model_weights_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9403045",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "outputs = model(torch.tensor([test_dataset[0]['input_ids'][:48]]).to('cuda:0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "445ba6e6",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[30,\n",
       " 10,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 9,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 19,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 9,\n",
       " 3,\n",
       " 5,\n",
       " 8,\n",
       " 11]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(outputs.logits[0], axis = 1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3635c799",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cleanrl",
   "language": "python",
   "name": "cleanrl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
